{"paragraphs":[{"text":"import org.apache.spark.ml._\nimport org.apache.spark.ml.feature._\nimport org.apache.spark.ml.regression._\nimport org.apache.spark.ml.regression.LinearRegression\nimport org.apache.spark.ml.regression.LinearRegressionModel\nimport org.apache.spark.ml.feature.{OneHotEncoder, StringIndexer}\nimport org.apache.spark.ml.feature.ChiSqSelector\nimport org.apache.spark.mllib.linalg.Vectors\nimport org.apache.spark.mllib.regression.LabeledPoint\nimport org.apache.spark.mllib.regression.LinearRegressionWithSGD\nimport org.apache.spark.ml.recommendation.ALS\nimport org.apache.spark.ml.evaluation.RegressionEvaluator\nimport org.apache.spark.mllib.recommendation.MatrixFactorizationModel\nimport org.apache.spark.mllib.recommendation.Rating\nimport org.apache.spark.mllib.recommendation.ALS\nimport org.apache.spark.mllib.classification.{NaiveBayes, NaiveBayesModel}\nimport org.apache.spark.mllib.util.MLUtils","dateUpdated":"Apr 10, 2017 12:12:49 AM","config":{"enabled":true,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"editorMode":"ace/mode/scala","colWidth":12},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1491272501577_458807873","id":"20170404-022141_699511436","result":{"code":"SUCCESS","type":"TEXT","msg":"import org.apache.spark.ml._\nimport org.apache.spark.ml.feature._\nimport org.apache.spark.ml.regression._\nimport org.apache.spark.ml.regression.LinearRegression\nimport org.apache.spark.ml.regression.LinearRegressionModel\nimport org.apache.spark.ml.feature.{OneHotEncoder, StringIndexer}\nimport org.apache.spark.ml.feature.ChiSqSelector\nimport org.apache.spark.mllib.linalg.Vectors\nimport org.apache.spark.mllib.regression.LabeledPoint\nimport org.apache.spark.mllib.regression.LinearRegressionWithSGD\nimport org.apache.spark.ml.recommendation.ALS\nimport org.apache.spark.ml.evaluation.RegressionEvaluator\nimport org.apache.spark.mllib.recommendation.MatrixFactorizationModel\nimport org.apache.spark.mllib.recommendation.Rating\nimport org.apache.spark.mllib.recommendation.ALS\nimport org.apache.spark.mllib.classification.{NaiveBayes, NaiveBayesModel}\nimport org.apache.spark.mllib.util.MLUtils\n"},"dateCreated":"Apr 4, 2017 2:21:41 AM","dateStarted":"Apr 9, 2017 2:30:22 PM","dateFinished":"Apr 9, 2017 2:30:52 PM","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:76"},{"text":"sqlContext.sql(\"Create database recommender\")","dateUpdated":"Apr 5, 2017 10:02:50 PM","config":{"enabled":true,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"editorMode":"ace/mode/scala","colWidth":12},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1491272501592_465348604","id":"20170404-022141_2037062909","result":{"code":"SUCCESS","type":"TEXT","msg":"res2: org.apache.spark.sql.DataFrame = [result: string]\n"},"dateCreated":"Apr 4, 2017 2:21:41 AM","dateStarted":"Apr 5, 2017 10:02:51 PM","dateFinished":"Apr 5, 2017 10:03:03 PM","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:77"},{"text":"sqlContext.sql(\"use recommender\")","dateUpdated":"Apr 9, 2017 2:31:16 PM","config":{"enabled":true,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"editorMode":"ace/mode/scala","colWidth":12},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1491272501594_466118102","id":"20170404-022141_1732011089","result":{"code":"SUCCESS","type":"TEXT","msg":"res189: org.apache.spark.sql.DataFrame = [result: string]\n"},"dateCreated":"Apr 4, 2017 2:21:41 AM","dateStarted":"Apr 9, 2017 2:31:17 PM","dateFinished":"Apr 9, 2017 2:31:20 PM","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:78"},{"text":"%hive\n\nCREATE EXTERNAL TABLE recommender.ratings (\n    artist INT,\n\ttrack INT,\n\tuserId INT,\n\trating DOUBLE,\n\ttime INT\n  )\nROW FORMAT DELIMITED\n\tFIELDS TERMINATED BY ','\n\tLINES TERMINATED BY '\\n'\nLOCATION '/user/lab/CapstoneProj/ratings'\ntblproperties (\"skip.header.line.count\"=\"1\")","dateUpdated":"Apr 5, 2017 10:18:36 PM","config":{"enabled":true,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[{"name":"Update Count","index":0,"aggr":"sum"}],"values":[],"groups":[],"scatter":{"xAxis":{"name":"Update Count","index":0,"aggr":"sum"}}},"editorMode":"ace/mode/scala","colWidth":12},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1491272501596_463809609","id":"20170404-022141_769537738","dateCreated":"Apr 4, 2017 2:21:41 AM","dateStarted":"Apr 5, 2017 10:18:37 PM","dateFinished":"Apr 5, 2017 10:19:50 PM","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:79"},{"text":"%hive\nLOAD DATA inpath '/user/lab/CapstoneProj/train_clean.csv' OVERWRITE INTO TABLE recommender.ratings","dateUpdated":"Apr 5, 2017 10:20:07 PM","config":{"enabled":true,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"editorMode":"ace/mode/scala","colWidth":12},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1491272501610_447650155","id":"20170404-022141_1474240332","dateCreated":"Apr 4, 2017 2:21:41 AM","dateStarted":"Apr 5, 2017 10:20:08 PM","dateFinished":"Apr 5, 2017 10:20:26 PM","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:80"},{"text":"%hive \r\n\r\nCREATE EXTERNAL TABLE recommender.wordsRating (\r\n   \tuserid2 STRING,\r\n\tartist2 STRING,\r\n\tavgRating DOUBLE,\r\n\theard_of STRING,\r\n\town_artist STRING,\r\n\tlike_artist STRING,\r\n\tAggressive INT,\r\n    Edgy INT,\r\n    Thoughtful INT,\r\n    Serious INT,\r\n    GoodLyrics INT,\r\n    Unattractive INT,\r\n    Confident INT,\r\n    Youthful INT,\r\n    Boring INT,\r\n    Current2 INT,\r\n    Cheap INT,\r\n    Calm INT,\r\n    Outgoing INT,\r\n    Inspiring INT,\r\n    Beautiful INT,\r\n    Fun INT,\r\n    Authentic INT,\r\n    Credible INT,\r\n    Cool INT,\r\n    Catchy INT,\r\n    Sensitive INT,\r\n    Superficial INT,\r\n    Passionate INT,\r\n    Timeless INT,\r\n    Depressing INT,\r\n    Original INT,\r\n    Talented INT,\r\n    Distinctive INT,\r\n    Approachable INT,\r\n    Trendsetter INT,\r\n    Noisy INT,\r\n    Upbeat INT,\r\n    Energetic INT,\r\n    None_of_these INT,\r\n    Sexy INT,\r\n    Over2 INT,\r\n    Fake INT,\r\n    Cheesy INT,\r\n    Unoriginal INT,\r\n    Dated INT,\r\n    Unapproachable INT,\r\n    Classic INT,\r\n    Playful INT,\r\n    Arrogant INT,\r\n    Warm INT,\r\n\tartistCluster INT\r\n  )\r\nROW FORMAT DELIMITED\r\n\tFIELDS TERMINATED BY ','\r\n\tLINES TERMINATED BY '\\n'\r\nLOCATION '/user/lab/CapstoneProj/wordsRating'","dateUpdated":"Apr 5, 2017 10:20:44 PM","config":{"enabled":true,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"editorMode":"ace/mode/scala","colWidth":12},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1491272501611_447265406","id":"20170404-022141_2038424485","dateCreated":"Apr 4, 2017 2:21:41 AM","dateStarted":"Apr 5, 2017 10:20:44 PM","dateFinished":"Apr 5, 2017 10:21:09 PM","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:81"},{"text":"%hive \nLOAD DATA inpath '/user/lab/CapstoneProj/ArtistDesc_clean.csv' OVERWRITE INTO TABLE recommender.wordsRating","dateUpdated":"Apr 5, 2017 10:21:57 PM","config":{"enabled":true,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"editorMode":"ace/mode/scala","colWidth":12},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1491272501612_445341662","id":"20170404-022141_993698804","dateCreated":"Apr 4, 2017 2:21:41 AM","dateStarted":"Apr 5, 2017 10:21:58 PM","dateFinished":"Apr 5, 2017 10:22:10 PM","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:82"},{"text":"%hive \r\n\r\nCREATE EXTERNAL TABLE recommender.userData (\r\n\tuserid STRING,\r\n\tartist STRING,\r\n\ttrack STRING,\r\n\trating DOUBLE,\r\n\ttime INT,\r\n\tgender STRING,\r\n\tage INT,\r\n\tworkingStatus STRING,\r\n\tregion STRING,\r\n\tmusic STRING,\r\n\tlist_own STRING,\r\n\tlist_back STRING,\r\n\tQ1 INT,\r\n\tQ2 INT,\r\n\tQ3 INT,\r\n\tQ4 INT,\r\n\tQ5 INT,\r\n\tQ6 INT,\r\n\tQ7 INT,\r\n\tQ8 INT,\r\n\tQ9 INT,\r\n\tQ10 INT,\r\n\tQ11 INT,\r\n\tQ12 INT,\r\n\tQ13 INT,\r\n\tQ14 INT,\r\n\tQ15 INT,\r\n\tQ16 INT,\r\n\tQ17 INT,\r\n\tQ18 INT,\r\n\tQ19 INT,\r\n\tList_Own2 INT,\r\n\tList_Back2 INT,\r\n\tusercluster INT\r\n  )\r\n\r\nROW FORMAT DELIMITED\r\n\tFIELDS TERMINATED BY ','\r\n\tLINES TERMINATED BY '\\n'\r\nLOCATION '/user/lab/CapstoneProj/userData'\r\n","dateUpdated":"Apr 5, 2017 10:22:25 PM","config":{"enabled":true,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"editorMode":"ace/mode/scala","colWidth":12},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1491272501614_446111159","id":"20170404-022141_115476109","dateCreated":"Apr 4, 2017 2:21:41 AM","dateStarted":"Apr 5, 2017 10:22:26 PM","dateFinished":"Apr 5, 2017 10:22:45 PM","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:83"},{"text":"%hive\nLOAD DATA inpath '/user/lab/CapstoneProj/trainData_clean.csv' OVERWRITE INTO TABLE recommender.userData","dateUpdated":"Apr 5, 2017 10:23:03 PM","config":{"enabled":true,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"editorMode":"ace/mode/scala","colWidth":12},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1491272501614_446111159","id":"20170404-022141_1629230722","dateCreated":"Apr 4, 2017 2:21:41 AM","dateStarted":"Apr 5, 2017 10:23:04 PM","dateFinished":"Apr 5, 2017 10:23:17 PM","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:84"},{"text":"val u = sqlContext.table(\"userData\")\nval ad = sqlContext.table(\"wordsRating\")\nval r = sqlContext.table(\"ratings\")\n","dateUpdated":"Apr 10, 2017 12:03:02 AM","config":{"enabled":true,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"editorMode":"ace/mode/scala","colWidth":12},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1491272501615_445726411","id":"20170404-022141_2064245404","result":{"code":"SUCCESS","type":"TEXT","msg":"u: org.apache.spark.sql.DataFrame = [userid: string, artist: string, track: string, rating: double, time: int, gender: string, age: int, workingstatus: string, region: string, music: string, list_own: string, list_back: string, q1: int, q2: int, q3: int, q4: int, q5: int, q6: int, q7: int, q8: int, q9: int, q10: int, q11: int, q12: int, q13: int, q14: int, q15: int, q16: int, q17: int, q18: int, q19: int, list_own2: int, list_back2: int, usercluster: int]\nad: org.apache.spark.sql.DataFrame = [userid2: string, artist2: string, avgrating: double, heard_of: string, own_artist: string, like_artist: string, aggressive: int, edgy: int, thoughtful: int, serious: int, goodlyrics: int, unattractive: int, confident: int, youthful: int, boring: int, current2: int, cheap: int, calm: int, outgoing: int, inspiring: int, beautiful: int, fun: int, authentic: int, credible: int, cool: int, catchy: int, sensitive: int, superficial: int, passionate: int, timeless: int, depressing: int, original: int, talented: int, distinctive: int, approachable: int, trendsetter: int, noisy: int, upbeat: int, energetic: int, none_of_these: int, sexy: int, over2: int, fake: int, cheesy: int, unoriginal: int, dated: int, unapproachable: int, classic: int, playful: int, arro...r: org.apache.spark.sql.DataFrame = [artist: int, track: int, userid: int, rating: double, time: int]\n"},"dateCreated":"Apr 4, 2017 2:21:41 AM","dateStarted":"Apr 8, 2017 3:20:34 PM","dateFinished":"Apr 8, 2017 3:20:42 PM","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:85"},{"text":"// Transform Gender into Numeric Index\nval gend_ind = new StringIndexer().\n    setInputCol(\"gender\").\n    setOutputCol(\"genderIndex\").\n    fit(u)\n\nval u2 = gend_ind.transform(u)\n\n\n// Transform Music into Numeric Index\nval music_ind = new StringIndexer().\n    setInputCol(\"music\").\n    setOutputCol(\"musicIndex\").\n    fit(u2)\n    \nval u3 = music_ind.transform(u2)","dateUpdated":"Apr 10, 2017 12:16:22 AM","config":{"enabled":true,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"editorMode":"ace/mode/scala","colWidth":12},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1491272501622_455345133","id":"20170404-022141_1174187743","result":{"code":"SUCCESS","type":"TEXT","msg":"gend_ind: org.apache.spark.ml.feature.StringIndexerModel = strIdx_8a97ff63402d\nu2: org.apache.spark.sql.DataFrame = [userid: string, artist: string, track: string, rating: double, time: int, gender: string, age: int, workingstatus: string, region: string, music: string, list_own: string, list_back: string, q1: int, q2: int, q3: int, q4: int, q5: int, q6: int, q7: int, q8: int, q9: int, q10: int, q11: int, q12: int, q13: int, q14: int, q15: int, q16: int, q17: int, q18: int, q19: int, list_own2: int, list_back2: int, usercluster: int, genderIndex: double]\nmusic_ind: org.apache.spark.ml.feature.StringIndexerModel = strIdx_1b111872dc3a\nu3: org.apache.spark.sql.DataFrame = [userid: string, artist: string, track: string, rating: double, time: int, gender: string, age: int, workingstatus: string, region: string, music: string, list_own: string, list_back: string, q1: int, q2: int, q3: int, q4: int, q5: int, q6: int, q7: int, q8: int, q9: int, q10: int, q11: int, q12: int, q13: int, q14: int, q15: int, q16: int, q17: int, q18: int, q19: int, list_own2: int, list_back2: int, usercluster: int, genderIndex: double, musicIndex: double]\n"},"dateCreated":"Apr 4, 2017 2:21:41 AM","dateStarted":"Apr 8, 2017 3:21:14 PM","dateFinished":"Apr 8, 2017 3:22:14 PM","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:86"},{"text":"// Transform Heard_Of into Numeric Index\nval heard_ind = new StringIndexer().\n    setInputCol(\"heard_of\").\n    setOutputCol(\"heardIndex\").\n    fit(ad)\n    \nval ad2 = heard_ind.transform(ad)\n","dateUpdated":"Apr 8, 2017 3:23:05 PM","config":{"enabled":true,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"editorMode":"ace/mode/scala","colWidth":12},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1491272501624_453036640","id":"20170404-022141_1346164318","result":{"code":"SUCCESS","type":"TEXT","msg":"heard_ind: org.apache.spark.ml.feature.StringIndexerModel = strIdx_04cb863b3c2c\nad2: org.apache.spark.sql.DataFrame = [userid2: string, artist2: string, avgrating: double, heard_of: string, own_artist: string, like_artist: string, aggressive: int, edgy: int, thoughtful: int, serious: int, goodlyrics: int, unattractive: int, confident: int, youthful: int, boring: int, current2: int, cheap: int, calm: int, outgoing: int, inspiring: int, beautiful: int, fun: int, authentic: int, credible: int, cool: int, catchy: int, sensitive: int, superficial: int, passionate: int, timeless: int, depressing: int, original: int, talented: int, distinctive: int, approachable: int, trendsetter: int, noisy: int, upbeat: int, energetic: int, none_of_these: int, sexy: int, over2: int, fake: int, cheesy: int, unoriginal: int, dated: int, unapproachable: int, classic: int, playful: int, arr..."},"dateCreated":"Apr 4, 2017 2:21:41 AM","dateStarted":"Apr 8, 2017 3:23:06 PM","dateFinished":"Apr 8, 2017 3:23:15 PM","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:87"},{"text":"//Save Gender Indexer\ngend_ind.save(\"/user/lab/CapstoneProj/genderIndexer\")\n\n//Save Music Indexer\nmusic_ind.save(\"/user/lab/CapstoneProj/musicIndexer\")\n\n//Save Heard Of Indexer\nheard_ind.save(\"/user/lab/CapstoneProj/heardIndexer\")","dateUpdated":"Apr 5, 2017 10:27:47 PM","config":{"enabled":true,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"colWidth":12},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1491272501625_452651891","id":"20170404-022141_1243471481","result":{"code":"SUCCESS","type":"TEXT","msg":""},"dateCreated":"Apr 4, 2017 2:21:41 AM","dateStarted":"Apr 5, 2017 10:27:47 PM","dateFinished":"Apr 5, 2017 10:28:11 PM","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:88"},{"text":"\n//Create Array of Features variables for Artist Descriptors Table\nval ad_features = Array(\"heardIndex\", \"aggressive\", \"edgy\", \"thoughtful\", \"serious\", \"goodlyrics\", \"unattractive\", \"confident\", \"youthful\", \"boring\", \"current2\", \"cheap\", \"calm\", \"outgoing\", \"inspiring\", \"beautiful\", \"fun\", \"authentic\", \"credible\", \"cool\", \"catchy\", \"sensitive\", \"superficial\", \"passionate\", \"timeless\", \"depressing\", \"original\", \"talented\", \"distinctive\", \"approachable\", \"trendsetter\", \"noisy\", \"upbeat\", \"energetic\", \"none_of_these\", \"sexy\", \"over2\", \"fake\", \"cheesy\", \"unoriginal\", \"dated\", \"unapproachable\", \"classic\", \"playful\", \"arrogant\", \"warm\")\n\n\n//Fill in Null Values\nval ad3 = ad2.na.fill(0)\n\nval ad4 = ad3.withColumn(\"label\", ad3(\"avgRating\"))\n\nval ad_vec = new VectorAssembler().\n    setInputCols(ad_features).\n    setOutputCol(\"features\").\n    transform(ad4)","dateUpdated":"Apr 10, 2017 12:17:23 AM","config":{"enabled":true,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"editorMode":"ace/mode/scala","colWidth":12},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1491272501625_452651891","id":"20170404-022141_1861812210","result":{"code":"SUCCESS","type":"TEXT","msg":"ad_features: Array[String] = Array(heardIndex, aggressive, edgy, thoughtful, serious, goodlyrics, unattractive, confident, youthful, boring, current2, cheap, calm, outgoing, inspiring, beautiful, fun, authentic, credible, cool, catchy, sensitive, superficial, passionate, timeless, depressing, original, talented, distinctive, approachable, trendsetter, noisy, upbeat, energetic, none_of_these, sexy, over2, fake, cheesy, unoriginal, dated, unapproachable, classic, playful, arrogant, warm)\nad3: org.apache.spark.sql.DataFrame = [userid2: string, artist2: string, avgrating: double, heard_of: string, own_artist: string, like_artist: string, aggressive: int, edgy: int, thoughtful: int, serious: int, goodlyrics: int, unattractive: int, confident: int, youthful: int, boring: int, current2: int, cheap: int, calm: int, outgoing: int, inspiring: int, beautiful: int, fun: int, authentic: int, credible: int, cool: int, catchy: int, sensitive: int, superficial: int, passionate: int, timeless: int, depressing: int, original: int, talented: int, distinctive: int, approachable: int, trendsetter: int, noisy: int, upbeat: int, energetic: int, none_of_these: int, sexy: int, over2: int, fake: int, cheesy: int, unoriginal: int, dated: int, unapproachable: int, classic: int, playful: int, arr...ad4: org.apache.spark.sql.DataFrame = [userid2: string, artist2: string, avgrating: double, heard_of: string, own_artist: string, like_artist: string, aggressive: int, edgy: int, thoughtful: int, serious: int, goodlyrics: int, unattractive: int, confident: int, youthful: int, boring: int, current2: int, cheap: int, calm: int, outgoing: int, inspiring: int, beautiful: int, fun: int, authentic: int, credible: int, cool: int, catchy: int, sensitive: int, superficial: int, passionate: int, timeless: int, depressing: int, original: int, talented: int, distinctive: int, approachable: int, trendsetter: int, noisy: int, upbeat: int, energetic: int, none_of_these: int, sexy: int, over2: int, fake: int, cheesy: int, unoriginal: int, dated: int, unapproachable: int, classic: int, playful: int, arr...ad_vec: org.apache.spark.sql.DataFrame = [userid2: string, artist2: string, avgrating: double, heard_of: string, own_artist: string, like_artist: string, aggressive: int, edgy: int, thoughtful: int, serious: int, goodlyrics: int, unattractive: int, confident: int, youthful: int, boring: int, current2: int, cheap: int, calm: int, outgoing: int, inspiring: int, beautiful: int, fun: int, authentic: int, credible: int, cool: int, catchy: int, sensitive: int, superficial: int, passionate: int, timeless: int, depressing: int, original: int, talented: int, distinctive: int, approachable: int, trendsetter: int, noisy: int, upbeat: int, energetic: int, none_of_these: int, sexy: int, over2: int, fake: int, cheesy: int, unoriginal: int, dated: int, unapproachable: int, classic: int, playful: int, ..."},"dateCreated":"Apr 4, 2017 2:21:41 AM","dateStarted":"Apr 8, 2017 3:24:05 PM","dateFinished":"Apr 8, 2017 3:24:20 PM","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:89"},{"text":"//Split Artist Data Into Training and Test Sets\nval Array (ad_train, ad_test) = ad_vec.randomSplit(Array(0.7, 0.3))","dateUpdated":"Apr 8, 2017 3:25:16 PM","config":{"enabled":true,"graph":{"mode":"table","height":132,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"editorMode":"ace/mode/scala","colWidth":11},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1491272501627_453421389","id":"20170404-022141_493593033","result":{"code":"SUCCESS","type":"TEXT","msg":"ad_train: org.apache.spark.sql.DataFrame = [userid2: string, artist2: string, avgrating: double, heard_of: string, own_artist: string, like_artist: string, aggressive: int, edgy: int, thoughtful: int, serious: int, goodlyrics: int, unattractive: int, confident: int, youthful: int, boring: int, current2: int, cheap: int, calm: int, outgoing: int, inspiring: int, beautiful: int, fun: int, authentic: int, credible: int, cool: int, catchy: int, sensitive: int, superficial: int, passionate: int, timeless: int, depressing: int, original: int, talented: int, distinctive: int, approachable: int, trendsetter: int, noisy: int, upbeat: int, energetic: int, none_of_these: int, sexy: int, over2: int, fake: int, cheesy: int, unoriginal: int, dated: int, unapproachable: int, classic: int, playful: int..."},"dateCreated":"Apr 4, 2017 2:21:41 AM","dateStarted":"Apr 8, 2017 3:25:17 PM","dateFinished":"Apr 8, 2017 3:25:23 PM","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:90"},{"text":"ad_train.show(5)\nad_test.show(5)","dateUpdated":"Apr 4, 2017 2:21:41 AM","config":{"enabled":true,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"editorMode":"ace/mode/scala","colWidth":12},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1491272501629_451112895","id":"20170404-022141_88777270","dateCreated":"Apr 4, 2017 2:21:41 AM","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:91"},{"text":"//Create Regression Model of Artist Data\nval ad_glr = new LinearRegression().\n    setMaxIter(10).\n    setRegParam(0.3).\n    setElasticNetParam(0.8).\n    fit(ad_train)\n    \n\n println(s\"Coefficients: ${ad_glr.coefficients}\")\n println(s\"Intercept: ${ad_glr.intercept}\")\n val trainingSummary = ad_glr.summary\nprintln(s\"numIterations: ${trainingSummary.totalIterations}\")\nprintln(s\"objectiveHistory: ${trainingSummary.objectiveHistory.toList}\")\ntrainingSummary.residuals.show()\nprintln(s\"RMSE: ${trainingSummary.rootMeanSquaredError}\")\nprintln(s\"MSE: ${trainingSummary.meanSquaredError}\")\nprintln(s\"MAE = ${trainingSummary.meanAbsoluteError}\")\nprintln(s\"Explained variance = ${trainingSummary.explainedVariance}\")\nprintln(s\"r2: ${trainingSummary.r2}\")\n","dateUpdated":"Apr 8, 2017 3:28:38 PM","config":{"enabled":true,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"editorMode":"ace/mode/scala","colWidth":12},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1491272501641_532679662","id":"20170404-022141_1725925872","result":{"code":"SUCCESS","type":"TEXT","msg":"ad_glr: org.apache.spark.ml.regression.LinearRegressionModel = linReg_b88fdb98d390\nCoefficients: [2.4710746203555973,-0.7580929849292373,0.621900341547144,0.28817780677518545,0.0,5.541609953240317,-6.14120365704947,1.2007606951294305,0.0,-9.167645380570061,0.0,-2.7945681158745037,0.5331614631628792,0.0,3.8334435584796913,9.25272664849097,3.8481348582375015,1.8271643202432117,0.9390368993099951,4.236383025233816,5.81532794517578,0.03465072675399789,-1.538239003045319,1.5263774831792223,3.960402617206642,-4.856427942000916,1.9263871621272928,3.716414944997949,3.4847878205504483,0.8353546224605721,0.3150818223414679,-5.755283581178408,1.0129405427086091,2.600248855789546,-8.359691844952371,1.6662271217479105,-0.19757916449935917,-1.3375144903028273,-3.748394354799606,-2.8153924792188185,-3.8508913965913694,-0.8857442818536365,1.8604358290763694,0.0,0.0,1.127364627478184]\nIntercept: 29.937278477029043\ntrainingSummary: org.apache.spark.ml.regression.LinearRegressionTrainingSummary = org.apache.spark.ml.regression.LinearRegressionTrainingSummary@4420e25c\nnumIterations: 11\nobjectiveHistory: List(0.4999926229750439, 0.4307469361124771, 0.2780419017018626, 0.27344518383165833, 0.2646514439662501, 0.2644316465105944, 0.2643770455997313, 0.2643506783188276, 0.26434693046318014, 0.2643465156819732, 0.26434638285919704)\n+-------------------+\n|          residuals|\n+-------------------+\n|  3.272133228963238|\n| -7.387447306460572|\n| 12.894033570510384|\n| 6.0391169545548635|\n|-12.915919872925713|\n|-10.769633096458982|\n|-17.048661252432268|\n| -2.077586632076674|\n|-11.077586632076674|\n|  8.422413367923326|\n|  9.309994874479983|\n|-14.577586632076674|\n| 16.485870748896637|\n| 24.770834853281116|\n|-17.769633096458982|\n|  16.95370526991276|\n|-7.3596194382520395|\n|-28.937278477029043|\n| 10.422413367923326|\n|  8.755746697923325|\n+-------------------+\nonly showing top 20 rows\n\nRMSE: 15.231679756932488\nMSE: 232.00406821774695\nMAE = 11.987688666610486\nExplained variance = 222.3067798286776\nr2: 0.5085415239903526\n"},"dateCreated":"Apr 4, 2017 2:21:41 AM","dateStarted":"Apr 8, 2017 3:28:39 PM","dateFinished":"Apr 8, 2017 3:30:36 PM","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:92"},{"text":"//Save Artist Descriptors Regression Model\nad_glr.save(\"/user/lab/CapstoneProj/adRegressionModel\")\n","dateUpdated":"Apr 10, 2017 12:18:46 AM","config":{"enabled":true,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"editorMode":"ace/mode/scala","colWidth":12},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1491272501645_531140666","id":"20170404-022141_1507416391","result":{"code":"SUCCESS","type":"TEXT","msg":""},"dateCreated":"Apr 4, 2017 2:21:41 AM","dateStarted":"Apr 5, 2017 10:36:15 PM","dateFinished":"Apr 5, 2017 10:36:23 PM","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:93"},{"text":"//Load Model\nval sameModel = LinearRegressionModel.load(\"/user/lab/CapstoneProj/adRegressionModel\")\n","dateUpdated":"Apr 4, 2017 2:21:41 AM","config":{"enabled":true,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"colWidth":12},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1491272501652_540759389","id":"20170404-022141_1282699878","dateCreated":"Apr 4, 2017 2:21:41 AM","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:94"},{"text":"val adtest_eval = ad_glr.transform(ad_test)","dateUpdated":"Apr 8, 2017 3:31:21 PM","config":{"enabled":true,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"editorMode":"ace/mode/scala","colWidth":12},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1491272501654_541528887","id":"20170404-022141_1896000960","result":{"code":"SUCCESS","type":"TEXT","msg":"adtest_eval: org.apache.spark.sql.DataFrame = [userid2: string, artist2: string, avgrating: double, heard_of: string, own_artist: string, like_artist: string, aggressive: int, edgy: int, thoughtful: int, serious: int, goodlyrics: int, unattractive: int, confident: int, youthful: int, boring: int, current2: int, cheap: int, calm: int, outgoing: int, inspiring: int, beautiful: int, fun: int, authentic: int, credible: int, cool: int, catchy: int, sensitive: int, superficial: int, passionate: int, timeless: int, depressing: int, original: int, talented: int, distinctive: int, approachable: int, trendsetter: int, noisy: int, upbeat: int, energetic: int, none_of_these: int, sexy: int, over2: int, fake: int, cheesy: int, unoriginal: int, dated: int, unapproachable: int, classic: int, playful: ..."},"dateCreated":"Apr 4, 2017 2:21:41 AM","dateStarted":"Apr 8, 2017 3:31:22 PM","dateFinished":"Apr 8, 2017 3:31:26 PM","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:95"},{"text":"adtest_eval.select($\"userid2\", $\"artist2\", $\"avgrating\",$\"label\", $\"prediction\")\nval test_MSE = adtest_eval.select($\"label\", $\"prediction\").map(v => math.pow((v(0).asInstanceOf[Double] - v(1).asInstanceOf[Double]), 2)).mean()\nval test_RMSE = math.sqrt(test_MSE)\nval test_MAE = adtest_eval.select($\"label\", $\"prediction\").map(v => math.abs(v(0).asInstanceOf[Double] - v(1).asInstanceOf[Double])).mean()\nprintln(\"test Mean Squared Error = \" + test_MSE)\nprintln(\"test Root Mean Squared Error = \" + test_RMSE)\nprintln(\"test Mean Absolute Error = \" + test_MAE)","dateUpdated":"Apr 8, 2017 3:33:34 PM","config":{"enabled":true,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"editorMode":"ace/mode/scala","colWidth":12},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1491272501656_539220393","id":"20170404-022141_1725780534","result":{"code":"SUCCESS","type":"TEXT","msg":"res41: org.apache.spark.sql.DataFrame = [userid2: string, artist2: string, avgrating: double, label: double, prediction: double]\ntest_MSE: Double = 234.2924046191155\ntest_RMSE: Double = 15.306613100850086\ntest_MAE: Double = 12.02450221418396\ntest Mean Squared Error = 234.2924046191155\ntest Root Mean Squared Error = 15.306613100850086\ntest Mean Absolute Error = 12.02450221418396\n"},"dateCreated":"Apr 4, 2017 2:21:41 AM","dateStarted":"Apr 8, 2017 3:33:35 PM","dateFinished":"Apr 8, 2017 3:34:10 PM","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:96"},{"text":"\n//REGRESSION MODEL ON USER DATA\n//Create Array of Features variables\nval features = Array(\"genderIndex\", \"age\", \"musicIndex\", \"q1\", \"q2\", \"q3\", \"q4\", \"q7\", \"q8\", \"q10\", \"q11\", \"q12\", \"q13\", \"q14\", \"q15\", \"q16\", \"q17\", \"q18\", \"q19\")\n\n//Fill in Null Values\nval u4 = u3.na.fill(0)\n\nval u5 = u4.withColumn(\"label\", u4(\"rating\"))\n\nval u_vec = new VectorAssembler().\n    setInputCols(features).\n    setOutputCol(\"features\").\n    transform(u5)\n","dateUpdated":"Apr 9, 2017 2:53:00 PM","config":{"enabled":true,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"editorMode":"ace/mode/scala","colWidth":12},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1491272501670_523060939","id":"20170404-022141_564556928","result":{"code":"SUCCESS","type":"TEXT","msg":"features: Array[String] = Array(genderIndex, age, musicIndex, q1, q2, q3, q4, q7, q8, q10, q11, q12, q13, q14, q15, q16, q17, q18, q19)\nu4: org.apache.spark.sql.DataFrame = [userid: string, artist: string, track: string, rating: double, time: int, gender: string, age: int, workingstatus: string, region: string, music: string, list_own: string, list_back: string, q1: int, q2: int, q3: int, q4: int, q5: int, q6: int, q7: int, q8: int, q9: int, q10: int, q11: int, q12: int, q13: int, q14: int, q15: int, q16: int, q17: int, q18: int, q19: int, list_own2: int, list_back2: int, usercluster: int, genderIndex: double, musicIndex: double]\nu5: org.apache.spark.sql.DataFrame = [userid: string, artist: string, track: string, rating: double, time: int, gender: string, age: int, workingstatus: string, region: string, music: string, list_own: string, list_back: string, q1: int, q2: int, q3: int, q4: int, q5: int, q6: int, q7: int, q8: int, q9: int, q10: int, q11: int, q12: int, q13: int, q14: int, q15: int, q16: int, q17: int, q18: int, q19: int, list_own2: int, list_back2: int, usercluster: int, genderIndex: double, musicIndex: double, label: double]\nu_vec: org.apache.spark.sql.DataFrame = [userid: string, artist: string, track: string, rating: double, time: int, gender: string, age: int, workingstatus: string, region: string, music: string, list_own: string, list_back: string, q1: int, q2: int, q3: int, q4: int, q5: int, q6: int, q7: int, q8: int, q9: int, q10: int, q11: int, q12: int, q13: int, q14: int, q15: int, q16: int, q17: int, q18: int, q19: int, list_own2: int, list_back2: int, usercluster: int, genderIndex: double, musicIndex: double, label: double, features: vector]\n"},"dateCreated":"Apr 4, 2017 2:21:41 AM","dateStarted":"Apr 9, 2017 2:53:01 PM","dateFinished":"Apr 9, 2017 2:53:10 PM","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:97"},{"text":"//Split Data into Training and Test Data Set\nval Array (u_train, u_test) = u_vec.randomSplit(Array(0.7, 0.3))","dateUpdated":"Apr 9, 2017 2:53:31 PM","config":{"enabled":true,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"editorMode":"ace/mode/scala","colWidth":12},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1491272501680_529986420","id":"20170404-022141_925536450","result":{"code":"SUCCESS","type":"TEXT","msg":"u_train: org.apache.spark.sql.DataFrame = [userid: string, artist: string, track: string, rating: double, time: int, gender: string, age: int, workingstatus: string, region: string, music: string, list_own: string, list_back: string, q1: int, q2: int, q3: int, q4: int, q5: int, q6: int, q7: int, q8: int, q9: int, q10: int, q11: int, q12: int, q13: int, q14: int, q15: int, q16: int, q17: int, q18: int, q19: int, list_own2: int, list_back2: int, usercluster: int, genderIndex: double, musicIndex: double, label: double, features: vector]\nu_test: org.apache.spark.sql.DataFrame = [userid: string, artist: string, track: string, rating: double, time: int, gender: string, age: int, workingstatus: string, region: string, music: string, list_own: string, list_back: string, q1: int, q2: int, q3: in..."},"dateCreated":"Apr 4, 2017 2:21:41 AM","dateStarted":"Apr 9, 2017 2:53:32 PM","dateFinished":"Apr 9, 2017 2:53:36 PM","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:98"},{"text":"//Create Regression Model\nval user_glr = new LinearRegression().\n    setMaxIter(10).\n    setRegParam(0.3).\n    setElasticNetParam(0.8)\n    \n//Fit Model\n val user_model = user_glr.fit(u_train)\n \n println(s\"Coefficients: ${user_model.coefficients}\")\n println(s\"Intercept: ${user_model.intercept}\")\n \n val trainingSummary = user_model.summary\n\nprintln(s\"numIterations: ${trainingSummary.totalIterations}\")\nprintln(s\"objectiveHistory: ${trainingSummary.objectiveHistory.toList}\")\ntrainingSummary.residuals.show()\nprintln(s\"RMSE: ${trainingSummary.rootMeanSquaredError}\")\nprintln(s\"MSE: ${trainingSummary.meanSquaredError}\")\nprintln(s\"MAE = ${trainingSummary.meanAbsoluteError}\")\nprintln(s\"Explained variance = ${trainingSummary.explainedVariance}\")\nprintln(s\"r2: ${trainingSummary.r2}\")\n","dateUpdated":"Apr 9, 2017 2:54:23 PM","config":{"enabled":true,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"editorMode":"ace/mode/scala","colWidth":12},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1491272501683_530371169","id":"20170404-022141_1267059929","result":{"code":"SUCCESS","type":"TEXT","msg":"user_glr: org.apache.spark.ml.regression.LinearRegression = linReg_ef8a9ce2c53e\nuser_model: org.apache.spark.ml.regression.LinearRegressionModel = linReg_ef8a9ce2c53e\nCoefficients: [-0.020638100891947397,0.026643377388922366,-0.47817053522883834,0.019623359565583778,0.02548561096320804,0.0017530861924884742,0.01503591321851332,0.0023197927598262035,0.005110598615532183,6.715603704023886E-4,0.10155995352013893,0.009987829857449138,0.016701428947508628,0.0,0.0,0.06001733529917376,0.06676908049128912,-0.0037636256916459814,-0.022952853261492153]\nIntercept: 20.864036977239444\ntrainingSummary: org.apache.spark.ml.regression.LinearRegressionTrainingSummary = org.apache.spark.ml.regression.LinearRegressionTrainingSummary@29d78b6f\nnumIterations: 11\nobjectiveHistory: List(0.49999596050996215, 0.4827735194964662, 0.47601484224110274, 0.4745257999553043, 0.47263241580833154, 0.47227202168789717, 0.4721539346016282, 0.472101435041812, 0.4720638161728133, 0.47205752582548305, 0.4720550602517231)\n+-------------------+\n|          residuals|\n+-------------------+\n| 3.7149385504722083|\n| 25.308260386594515|\n| -7.358519000086758|\n| -7.358519000086758|\n| 18.531351261677543|\n| 2.5313512616775427|\n|-17.468648738322457|\n| 11.151314695224158|\n| 15.151314695224158|\n|-0.7385059897815296|\n| 3.2614940102184704|\n| 1.2614940102184704|\n|  32.55274711336917|\n|-30.447252886630828|\n|  33.55274711336917|\n|-30.447252886630828|\n| -21.34823990817098|\n|-2.3482399081709815|\n| 2.4873996345546843|\n|-16.512600365445316|\n+-------------------+\nonly showing top 20 rows\n\nRMSE: 21.860924792862264\nMSE: 477.90003279918005\nMAE = 17.800949922216777\nExplained variance = 28.3087156257203\nr2: 0.06524054122026202\n"},"dateCreated":"Apr 4, 2017 2:21:41 AM","dateStarted":"Apr 9, 2017 2:54:24 PM","dateFinished":"Apr 9, 2017 2:56:17 PM","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:99"},{"text":"//Evaluate Model on Test Data\r\nval u_eval = user_model.transform(u_test)\r\n\r\nu_eval.select($\"userid\", $\"artist\", $\"label\", $\"prediction\").show(10)\r\nval test_MSE = u_eval.select($\"label\", $\"prediction\").map(v => math.pow((v(0).asInstanceOf[Double] - v(1).asInstanceOf[Double]), 2)).mean()\r\nval test_RMSE = math.sqrt(test_MSE)\r\nval test_MAE = u_eval.select($\"label\", $\"prediction\").map(v => math.abs(v(0).asInstanceOf[Double] - v(1).asInstanceOf[Double])).mean()\r\nprintln(\"test Mean Squared Error = \" + test_MSE)\r\nprintln(\"test Root Mean Squared Error = \" + test_RMSE)\r\nprintln(\"test Mean Absolute Error = \" + test_MAE)","dateUpdated":"Apr 9, 2017 3:00:03 PM","config":{"enabled":true,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"editorMode":"ace/mode/scala","colWidth":12},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1491272501688_526908428","id":"20170404-022141_1085547101","result":{"code":"SUCCESS","type":"TEXT","msg":"u_eval: org.apache.spark.sql.DataFrame = [userid: string, artist: string, track: string, rating: double, time: int, gender: string, age: int, workingstatus: string, region: string, music: string, list_own: string, list_back: string, q1: int, q2: int, q3: int, q4: int, q5: int, q6: int, q7: int, q8: int, q9: int, q10: int, q11: int, q12: int, q13: int, q14: int, q15: int, q16: int, q17: int, q18: int, q19: int, list_own2: int, list_back2: int, usercluster: int, genderIndex: double, musicIndex: double, label: double, features: vector, prediction: double]\n+------+------+-----+------------------+\n|userid|artist|label|        prediction|\n+------+------+-----+------------------+\n|     0|     0| 32.0| 27.28506144952779|\n|     0|     0| 32.0| 27.28506144952779|\n|     1|     0| 28.0|23.691739613405485|\n|     1|     0| 27.0|23.691739613405485|\n|  1000|     0| 42.0| 36.84868530477584|\n| 10000|     9| 50.0| 47.73850598978153|\n| 10001|     9| 72.0| 40.44725288663083|\n| 10002|    11|  7.0| 31.34823990817098|\n| 10003|    11| 10.0|27.512600365445316|\n| 10004|     9| 49.0| 43.85512358041935|\n+------+------+-----+------------------+\nonly showing top 10 rows\n\ntest_MSE: Double = 478.77010577957714\ntest_RMSE: Double = 21.880815930389275\ntest_MAE: Double = 17.846959984547304\ntest Mean Squared Error = 478.77010577957714\ntest Root Mean Squared Error = 21.880815930389275\ntest Mean Absolute Error = 17.846959984547304\n"},"dateCreated":"Apr 4, 2017 2:21:41 AM","dateStarted":"Apr 9, 2017 3:00:04 PM","dateFinished":"Apr 9, 2017 3:00:42 PM","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:100"},{"text":"//REGRESSION MODEL ON JOINED DATA SET\n// Join Artist and User Ratings Tables\nval join_data = u4.join(ad3, u4(\"userid\") === ad3(\"userid2\") && u4(\"artist\") === ad3(\"artist2\"))\n","dateUpdated":"Apr 8, 2017 3:46:02 PM","config":{"enabled":true,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"editorMode":"ace/mode/scala","colWidth":12},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1491272501690_527677926","id":"20170404-022141_1916545242","result":{"code":"SUCCESS","type":"TEXT","msg":"join_data: org.apache.spark.sql.DataFrame = [userid: string, artist: string, track: string, rating: double, time: int, gender: string, age: int, workingstatus: string, region: string, music: string, list_own: string, list_back: string, q1: int, q2: int, q3: int, q4: int, q5: int, q6: int, q7: int, q8: int, q9: int, q10: int, q11: int, q12: int, q13: int, q14: int, q15: int, q16: int, q17: int, q18: int, q19: int, list_own2: int, list_back2: int, usercluster: int, genderIndex: double, musicIndex: double, userid2: string, artist2: string, avgrating: double, heard_of: string, own_artist: string, like_artist: string, aggressive: int, edgy: int, thoughtful: int, serious: int, goodlyrics: int, unattractive: int, confident: int, youthful: int, boring: int, current2: int, cheap: int, calm: int,..."},"dateCreated":"Apr 4, 2017 2:21:41 AM","dateStarted":"Apr 8, 2017 3:46:03 PM","dateFinished":"Apr 8, 2017 3:46:06 PM","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:101"},{"text":"//Create Array of Features variables\nval features = Array(\"genderIndex\", \"musicIndex\", \"q1\", \"q2\", \"q3\", \"q4\", \"q7\", \"q8\", \"q10\", \"q11\", \"q12\", \"q13\", \"q14\", \"q15\", \"q16\", \"q17\", \"q18\", \"q19\",\"heardIndex\", \"aggressive\", \"edgy\", \"thoughtful\", \"serious\", \"goodlyrics\", \"unattractive\", \"confident\", \"youthful\", \"boring\", \"current2\", \"cheap\", \"calm\", \"outgoing\", \"inspiring\", \"beautiful\", \"fun\", \"authentic\", \"credible\", \"cool\", \"catchy\", \"sensitive\", \"superficial\", \"passionate\", \"timeless\", \"depressing\", \"original\", \"talented\", \"distinctive\", \"approachable\", \"trendsetter\", \"noisy\", \"upbeat\", \"energetic\", \"none_of_these\", \"sexy\", \"over2\", \"fake\", \"cheesy\", \"unoriginal\", \"dated\", \"unapproachable\", \"classic\", \"playful\", \"arrogant\", \"warm\")\n\n\n//Fill in Null Values\nval join_data2 = join_data.na.fill(0)\n\n//Create Vector of Features\nval join_vec = new VectorAssembler().\n    setInputCols(features).\n    setOutputCol(\"features\").\n    transform(join_data2)","dateUpdated":"Apr 10, 2017 12:24:12 AM","config":{"enabled":true,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"editorMode":"ace/mode/scala","colWidth":12},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1491272501705_508055732","id":"20170404-022141_1268660941","result":{"code":"SUCCESS","type":"TEXT","msg":"features: Array[String] = Array(genderIndex, musicIndex, q1, q2, q3, q4, q7, q8, q10, q11, q12, q13, q14, q15, q16, q17, q18, q19, heardIndex, aggressive, edgy, thoughtful, serious, goodlyrics, unattractive, confident, youthful, boring, current2, cheap, calm, outgoing, inspiring, beautiful, fun, authentic, credible, cool, catchy, sensitive, superficial, passionate, timeless, depressing, original, talented, distinctive, approachable, trendsetter, noisy, upbeat, energetic, none_of_these, sexy, over2, fake, cheesy, unoriginal, dated, unapproachable, classic, playful, arrogant, warm)\njoin_data2: org.apache.spark.sql.DataFrame = [userid: string, artist: string, track: string, rating: double, time: int, gender: string, age: int, workingstatus: string, region: string, music: string, list_own: string, list_back: string, q1: int, q2: int, q3: int, q4: int, q5: int, q6: int, q7: int, q8: int, q9: int, q10: int, q11: int, q12: int, q13: int, q14: int, q15: int, q16: int, q17: int, q18: int, q19: int, list_own2: int, list_back2: int, usercluster: int, genderIndex: double, musicIndex: double, userid2: string, artist2: string, avgrating: double, heard_of: string, own_artist: string, like_artist: string, aggressive: int, edgy: int, thoughtful: int, serious: int, goodlyrics: int, unattractive: int, confident: int, youthful: int, boring: int, current2: int, cheap: int, calm: int...join_vec: org.apache.spark.sql.DataFrame = [userid: string, artist: string, track: string, rating: double, time: int, gender: string, age: int, workingstatus: string, region: string, music: string, list_own: string, list_back: string, q1: int, q2: int, q3: int, q4: int, q5: int, q6: int, q7: int, q8: int, q9: int, q10: int, q11: int, q12: int, q13: int, q14: int, q15: int, q16: int, q17: int, q18: int, q19: int, list_own2: int, list_back2: int, usercluster: int, genderIndex: double, musicIndex: double, userid2: string, artist2: string, avgrating: double, heard_of: string, own_artist: string, like_artist: string, aggressive: int, edgy: int, thoughtful: int, serious: int, goodlyrics: int, unattractive: int, confident: int, youthful: int, boring: int, current2: int, cheap: int, calm: int, ..."},"dateCreated":"Apr 4, 2017 2:21:41 AM","dateStarted":"Apr 9, 2017 10:31:13 PM","dateFinished":"Apr 9, 2017 10:31:31 PM","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:103","focus":true},{"text":"//CREATE SEPARATE TABLES FOR RATINGS AND AVERAGE RATINGS\r\nval join_rating = join_vec.select($\"userid\", $\"artist\", $\"rating\".alias(\"label\"), $\"features\")\r\n\r\nval join_avg = join_vec.select($\"userid\", $\"artist\", $\"avgrating\".alias(\"label\"), $\"features\")","dateUpdated":"Apr 9, 2017 10:33:07 PM","config":{"enabled":true,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"editorMode":"ace/mode/scala","colWidth":12},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1491272501732_497667512","id":"20170404-022141_177742771","result":{"code":"SUCCESS","type":"TEXT","msg":"join_rating: org.apache.spark.sql.DataFrame = [userid: string, artist: string, label: double, features: vector]\njoin_avg: org.apache.spark.sql.DataFrame = [userid: string, artist: string, label: double, features: vector]\n"},"dateCreated":"Apr 4, 2017 2:21:41 AM","dateStarted":"Apr 9, 2017 10:33:07 PM","dateFinished":"Apr 9, 2017 10:33:26 PM","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:105","focus":true},{"text":"//Model Joined Data On Ratings\r\n//Split Joined Data Set into Training and Test Data\r\nval Array (joinr_train, joinr_test) = join_rating.randomSplit(Array(0.7, 0.3))\r\n\r\n//Create Regression Model for Joined Dataset\r\nval joinr_glr = new LinearRegression().\r\n    setMaxIter(10).\r\n    setRegParam(0.3).\r\n    setElasticNetParam(0.8).\r\n    fit(joinr_train)\r\n \r\n println(s\"Coefficients: ${joinr_glr.coefficients}\")\r\n println(s\"Intercept: ${joinr_glr.intercept}\")\r\n\r\nval trainingSummary = joinr_glr.summary\r\nprintln(s\"numIterations: ${trainingSummary.totalIterations}\")\r\nprintln(s\"objectiveHistory: ${trainingSummary.objectiveHistory.toList}\")\r\nprintln(s\"RMSE: ${trainingSummary.rootMeanSquaredError}\")\r\nprintln(s\"MSE: ${trainingSummary.meanSquaredError}\")\r\nprintln(s\"MAE = ${trainingSummary.meanAbsoluteError}\")\r\nprintln(s\"Explained variance = ${trainingSummary.explainedVariance}\")\r\nprintln(s\"r2: ${trainingSummary.r2}\")\r\n\r\n//Evaluate Model on Test Data\r\nval joinrtest_eval = joinr_glr.transform(joinr_test)\r\n\r\nval test_MSE = joinrtest_eval.select($\"label\", $\"prediction\").map(v => math.pow((v(0).asInstanceOf[Double] - v(1).asInstanceOf[Double]), 2)).mean()\r\nval test_RMSE = math.sqrt(test_MSE)\r\nval test_MAE = joinrtest_eval.select($\"label\", $\"prediction\").map(v => math.abs(v(0).asInstanceOf[Double] - v(1).asInstanceOf[Double])).mean()\r\nprintln(\"test Mean Squared Error = \" + test_MSE)\r\nprintln(\"test Root Mean Squared Error = \" + test_RMSE)\r\nprintln(\"test Mean Absolute Error = \" + test_MAE)","dateUpdated":"Apr 9, 2017 8:29:26 PM","config":{"enabled":true,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"editorMode":"ace/mode/scala","colWidth":12},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1491272501738_496898014","id":"20170404-022141_172999220","dateCreated":"Apr 4, 2017 2:21:41 AM","dateStarted":"Apr 9, 2017 3:15:13 PM","dateFinished":"Apr 9, 2017 3:23:48 PM","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:106","errorMessage":"","focus":true},{"text":"//Save JoinedData Rating Regression Model\r\njoinr_glr.save(\"/user/lab/CapstoneProj/joinRatingRegModel\")","dateUpdated":"Apr 10, 2017 12:25:37 AM","config":{"enabled":true,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"colWidth":12,"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1491272501747_505747239","id":"20170404-022141_2052516149","dateCreated":"Apr 4, 2017 2:21:41 AM","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:107"},{"text":"//Model Joined Data On Average Ratings\r\n//Split Joined Data Set into Training and Test Data\r\nval Array (joina_train, joina_test) = join_avg.randomSplit(Array(0.7, 0.3))\r\n\r\n//Create Regression Model for Joined Dataset\r\nval joina_glr = new LinearRegression().\r\n    setMaxIter(10).\r\n    setRegParam(0.3).\r\n    setElasticNetParam(0.8).\r\n    fit(joina_train)\r\n \r\n println(s\"Coefficients: ${joina_glr.coefficients}\")\r\n println(s\"Intercept: ${joina_glr.intercept}\")\r\n\r\nval trainingSummary = joina_glr.summary\r\nprintln(s\"numIterations: ${trainingSummary.totalIterations}\")\r\nprintln(s\"objectiveHistory: ${trainingSummary.objectiveHistory.toList}\")\r\nprintln(s\"RMSE: ${trainingSummary.rootMeanSquaredError}\")\r\nprintln(s\"MSE: ${trainingSummary.meanSquaredError}\")\r\nprintln(s\"MAE = ${trainingSummary.meanAbsoluteError}\")\r\nprintln(s\"Explained variance = ${trainingSummary.explainedVariance}\")\r\nprintln(s\"r2: ${trainingSummary.r2}\")\r\n\r\n\r\nval joinatest_eval = joina_glr.transform(joina_test)\r\nval test_MSE = joinatest_eval.select($\"label\", $\"prediction\").map(v => math.pow((v(0).asInstanceOf[Double] - v(1).asInstanceOf[Double]), 2)).mean()\r\nval test_RMSE = math.sqrt(test_MSE)\r\nval test_MAE = joinatest_eval.select($\"label\", $\"prediction\").map(v => math.abs(v(0).asInstanceOf[Double] - v(1).asInstanceOf[Double])).mean()\r\nprintln(\"test Mean Squared Error = \" + test_MSE)\r\nprintln(\"test Root Mean Squared Error = \" + test_RMSE)\r\nprintln(\"test Mean Absolute Error = \" + test_MAE)","dateUpdated":"Apr 9, 2017 10:34:16 PM","config":{"enabled":true,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"editorMode":"ace/mode/scala","colWidth":12},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1491272501749_503438746","id":"20170404-022141_1609094482","result":{"code":"SUCCESS","type":"TEXT","msg":"joina_train: org.apache.spark.sql.DataFrame = [userid: string, artist: string, label: double, features: vector]\njoina_test: org.apache.spark.sql.DataFrame = [userid: string, artist: string, label: double, features: vector]\njoina_glr: org.apache.spark.ml.regression.LinearRegressionModel = linReg_15b6f823c763\nCoefficients: [0.0,0.0,0.005538799619663284,0.008993516239485992,0.0,0.021027265832930627,5.985093431563689E-4,0.014470524474537274,3.0026390087889237E-4,0.03528404408253593,0.010627712750746627,0.002641181643922619,0.0,0.003962564096324433,0.030180220636277233,0.014487330500042738,-0.0,0.0,1.1071366256552748,-0.6502903736551271,0.06108303866184824,0.42938383511435335,0.0,5.537446850262434,-5.400225350890115,1.4228501053059837,0.0,-8.159675690418165,0.0,-2.2366640542954035,0.19717304527163568,0.0,3.426497649099324,8.954006976565063,3.33430546960248,2.0979309023801727,0.9390685776541734,3.6494580190819423,6.404278868941812,-0.0,-1.2906013848629057,0.9412552970557208,5.182102512799025,-5.254356190082121,1.9650375211303852,3.815633808749992,3.6194067977595736,0.9041401015287531,0.0,-5.163915689481846,1.1463190103723264,2.061981088776016,-7.486166870986469,1.9180831257252333,-0.0038198734145556104,-1.3388124194073743,-3.2741348378408266,-2.7928000984895207,-3.532542758440478,-0.431205870785306,1.9148984163778877,0.0,0.0,1.3775433475828072]\nIntercept: 23.93986752142121\ntrainingSummary: org.apache.spark.ml.regression.LinearRegressionTrainingSummary = org.apache.spark.ml.regression.LinearRegressionTrainingSummary@ccccd01\nnumIterations: 11\nobjectiveHistory: List(0.49999591379747177, 0.4276828028688272, 0.2733956773743214, 0.26925338753510597, 0.2615642028994168, 0.26085102913355773, 0.2603710252721205, 0.2603234461980701, 0.2602695333017668, 0.26024692700248825, 0.2602427488785701)\nRMSE: 14.604010006048897\nMSE: 213.2771082567763\nMAE = 11.48674271279861\nExplained variance = 213.46601575199978\nr2: 0.5202417151641596\njoinatest_eval: org.apache.spark.sql.DataFrame = [userid: string, artist: string, label: double, features: vector, prediction: double]\ntest_MSE: Double = 213.6481950931286\ntest_RMSE: Double = 14.616709448201007\ntest_MAE: Double = 11.492771149980614\ntest Mean Squared Error = 213.6481950931286\ntest Root Mean Squared Error = 14.616709448201007\ntest Mean Absolute Error = 11.492771149980614\n"},"dateCreated":"Apr 4, 2017 2:21:41 AM","dateStarted":"Apr 9, 2017 10:34:16 PM","dateFinished":"Apr 9, 2017 10:47:36 PM","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:108","focus":true},{"text":"//Save JoinedData Average Rating Regression Model\r\njoina_glr.save(\"/user/lab/CapstoneProj/joinedAvgRegModel\")\r\n","dateUpdated":"Apr 9, 2017 11:48:35 PM","config":{"enabled":true,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"editorMode":"ace/mode/scala","colWidth":12},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1491272501754_503053997","id":"20170404-022141_789392303","result":{"code":"SUCCESS","type":"TEXT","msg":""},"dateCreated":"Apr 4, 2017 2:21:41 AM","dateStarted":"Apr 9, 2017 11:48:35 PM","dateFinished":"Apr 9, 2017 11:48:49 PM","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:109","focus":true},{"config":{"colWidth":12,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true,"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1491770016647_2037884714","id":"20170409-203336_1919902183","dateCreated":"Apr 9, 2017 8:33:36 PM","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:1497","text":"val globalAvg = r.agg(avg(\"rating\").alias(\"avgRating\"))\nglobalAvg.show()","dateUpdated":"Apr 9, 2017 8:34:59 PM","dateFinished":"Apr 9, 2017 8:35:13 PM","dateStarted":"Apr 9, 2017 8:34:59 PM","result":{"code":"SUCCESS","type":"TEXT","msg":"globalAvg: org.apache.spark.sql.DataFrame = [avgRating: double]\n+------------------+\n|         avgRating|\n+------------------+\n|36.435391382691186|\n+------------------+\n\n"}},{"text":"//Calcualte Error Metrics for predictions of Global Average Ratings\r\nval test_MSE = join_avg.select($\"label\").map(v => math.pow((v(0).asInstanceOf[Double] - 36.44), 2)).mean()\r\nval test_RMSE = math.sqrt(test_MSE)\r\nval test_MAE = join_avg.select($\"label\").map(v => math.abs(v(0).asInstanceOf[Double] - 36.44)).mean()\r\nprintln(\"test Mean Squared Error = \" + test_MSE)\r\nprintln(\"test Root Mean Squared Error = \" + test_RMSE)\r\nprintln(\"test Mean Absolute Error = \" + test_MAE)","dateUpdated":"Apr 5, 2017 11:28:21 PM","config":{"colWidth":12,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true,"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1491434813777_353841943","id":"20170405-232653_611275829","result":{"code":"SUCCESS","type":"TEXT","msg":"test_MSE: Double = 446.3074866614578\ntest_RMSE: Double = 21.125990785320763\ntest_MAE: Double = 17.169317143907048\ntest Mean Squared Error = 446.3074866614578\ntest Root Mean Squared Error = 21.125990785320763\ntest Mean Absolute Error = 17.169317143907048\n"},"dateCreated":"Apr 5, 2017 11:26:53 PM","dateStarted":"Apr 5, 2017 11:28:21 PM","dateFinished":"Apr 5, 2017 11:28:56 PM","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:113"},{"text":"//Calcualte Error Metrics for predictions of Global Average Ratings\r\nval test_MSE = r.select($\"rating\").map(v => math.pow((v(0).asInstanceOf[Double] - 36.44), 2)).mean()\r\nval test_RMSE = math.sqrt(test_MSE)\r\nval test_MAE = r.select($\"rating\").map(v => math.abs(v(0).asInstanceOf[Double] - 36.44)).mean()\r\nprintln(\"test Mean Squared Error = \" + test_MSE)\r\nprintln(\"test Root Mean Squared Error = \" + test_RMSE)\r\nprintln(\"test Mean Absolute Error = \" + test_MAE)","dateUpdated":"Apr 4, 2017 2:21:41 AM","config":{"enabled":true,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"editorMode":"ace/mode/scala","colWidth":12},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1491272501774_187559899","id":"20170404-022141_1954866073","result":{"code":"SUCCESS","type":"TEXT","msg":"test_MSE: Double = 510.126349377279\ntest_RMSE: Double = 22.585976830265256\ntest_MAE: Double = 18.590786581164835\ntest Mean Squared Error = 510.126349377279\ntest Root Mean Squared Error = 22.585976830265256\ntest Mean Absolute Error = 18.590786581164835\n"},"dateCreated":"Apr 4, 2017 2:21:41 AM","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:114"},{"text":"import org.apache.spark.ml.feature.Bucketizer\r\nimport org.apache.spark.mllib.classification.{NaiveBayes, NaiveBayesModel}\r\nimport org.apache.spark.mllib.util.MLUtils\r\nimport org.apache.spark.mllib.evaluation.MulticlassMetrics\r\nimport org.apache.spark.mllib.regression.LabeledPoint","dateUpdated":"Apr 9, 2017 9:01:40 PM","config":{"enabled":true,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"colWidth":12,"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1491272501866_152163000","id":"20170404-022141_549157612","result":{"code":"SUCCESS","type":"TEXT","msg":"import org.apache.spark.mllib.classification.{NaiveBayes, NaiveBayesModel}\nimport org.apache.spark.mllib.util.MLUtils\n"},"dateCreated":"Apr 4, 2017 2:21:41 AM","dateStarted":"Apr 8, 2017 4:06:54 PM","dateFinished":"Apr 8, 2017 4:06:57 PM","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:132"},{"text":"//NAIVE BAYES CLASSIFICATION OF AVERAGE RATINGS - Joined Data Set 4 Categories\r\nval naivejoin_avg = join_vec.select($\"userid\", $\"artist\", $\"avgrating\", $\"features\")\r\n\r\nval splits = Array(0.0, 25.0, 50.0, 75.0, 100.0)\r\nval bucketed_data = new Bucketizer().\r\n    setInputCol(\"avgrating\").\r\n    setOutputCol(\"label\").\r\n    setSplits(splits).\r\n    transform(naivejoin_avg)\r\n    \r\nval Array (joina_trainNaive, joina_testNaive) = bucketed_data.randomSplit(Array(0.7, 0.3))\r\n\r\nval bucketed_train = joina_trainNaive.select($\"userid\", $\"artist\", $\"avgrating\", $\"features\", $\"label\").rdd.map(row => LabeledPoint(row.getAs[Double](\"label\"), row.getAs[org.apache.spark.mllib.linalg.Vector](\"features\")))\r\n\r\nval bucketed_test = joina_testNaive.select($\"userid\", $\"artist\", $\"avgrating\", $\"features\", $\"label\").rdd.map(row => LabeledPoint(row.getAs[Double](\"label\"), row.getAs[org.apache.spark.mllib.linalg.Vector](\"features\")))\r\n   \r\nval nb_model = NaiveBayes.train(bucketed_train, lambda = 1.0, modelType = \"multinomial\")\r\n\r\nval prediction_label = bucketed_test.map(p=> (nb_model.predict(p.features), p.label))\r\nval accuracy = 1.0 * prediction_label.filter(x => x._1 == x._2).count() / bucketed_test.count()\r\n\r\n// Instantiate metrics object\r\nval metrics = new MulticlassMetrics(prediction_label)\r\n\r\n// Confusion matrix\r\nprintln(\"Confusion matrix:\")\r\nprintln(metrics.confusionMatrix)\r\n\r\n// Precision by label\r\nval labels = metrics.labels\r\nlabels.foreach { l =>\r\n  println(s\"Precision($l) = \" + metrics.precision(l))\r\n}\r\n\r\n// Recall by label\r\nlabels.foreach { l =>\r\n  println(s\"Recall($l) = \" + metrics.recall(l))\r\n}\r\n\r\n// False positive rate by label\r\nlabels.foreach { l =>\r\n  println(s\"FPR($l) = \" + metrics.falsePositiveRate(l))\r\n}\r\n\r\n// F-measure by label\r\nlabels.foreach { l =>\r\n  println(s\"F1-Score($l) = \" + metrics.fMeasure(l))\r\n}\r\n\r\n// Weighted stats\r\nprintln(s\"Weighted precision: ${metrics.weightedPrecision}\")\r\nprintln(s\"Weighted recall: ${metrics.weightedRecall}\")\r\nprintln(s\"Weighted F1 score: ${metrics.weightedFMeasure}\")\r\nprintln(s\"Weighted false positive rate: ${metrics.weightedFalsePositiveRate}\")","dateUpdated":"Apr 9, 2017 9:48:33 PM","config":{"enabled":true,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"editorMode":"ace/mode/scala","colWidth":12},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1491272501867_151778251","id":"20170404-022141_1954753725","result":{"code":"SUCCESS","type":"TEXT","msg":"naivejoin_avg: org.apache.spark.sql.DataFrame = [userid: string, artist: string, avgrating: double, features: vector]\nsplits: Array[Double] = Array(0.0, 25.0, 50.0, 75.0, 100.0)\nbucketed_data: org.apache.spark.sql.DataFrame = [userid: string, artist: string, avgrating: double, features: vector, label: double]\njoina_trainNaive: org.apache.spark.sql.DataFrame = [userid: string, artist: string, avgrating: double, features: vector, label: double]\njoina_testNaive: org.apache.spark.sql.DataFrame = [userid: string, artist: string, avgrating: double, features: vector, label: double]\nbucketed_train: org.apache.spark.rdd.RDD[org.apache.spark.mllib.regression.LabeledPoint] = MapPartitionsRDD[467] at map at <console>:58\nbucketed_test: org.apache.spark.rdd.RDD[org.apache.spark.mllib.regression.LabeledPoint] = MapPartitionsRDD[486] at map at <console>:58\nnb_model: org.apache.spark.mllib.classification.NaiveBayesModel = org.apache.spark.mllib.classification.NaiveBayesModel@483c4c48\nprediction_label: org.apache.spark.rdd.RDD[(Double, Double)] = MapPartitionsRDD[489] at map at <console>:66\naccuracy: Double = 0.3994707980212448\n"},"dateCreated":"Apr 4, 2017 2:21:41 AM","dateStarted":"Apr 8, 2017 4:07:12 PM","dateFinished":"Apr 8, 2017 4:10:36 PM","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:133","focus":true},{"config":{"colWidth":12,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true,"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1491774320143_5585707","id":"20170409-214520_1656928086","dateCreated":"Apr 9, 2017 9:45:20 PM","status":"READY","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:1758","text":"//Distribution of Ratings in Data Set\njoina_trainNaive.groupBy($\"label\").agg(count($\"label\").alias(\"Count\"),((count($\"label\")/joina_trainNaive.count())*100).alias(\"Percent\")).orderBy($\"label\".asc).show()\njoina_testNaive.groupBy($\"label\").agg(count($\"label\").alias(\"Count\"),((count($\"label\")/joina_testNaive.count())*100).alias(\"Percent\")).orderBy($\"label\".asc).show()\nbucketed_data.groupBy($\"label\").agg(count($\"label\").alias(\"Count\"),((count($\"label\")/bucketed_data.count())*100).alias(\"Percent\")).orderBy($\"label\".asc).show()","dateUpdated":"Apr 9, 2017 9:47:50 PM"},{"text":"//NAIVE BAYES CLASSIFICATION OF AVG RATINGS USING ARTIST DESCRIPTORS ONLY 4 Categories\r\nval naive_ad = ad_vec.select($\"userid2\", $\"artist2\", $\"avgrating\", $\"features\")\r\n\r\nval splits = Array(0.0, 25.0, 50.0, 75.0, 100.0)\r\nval bucketed_data3 = new Bucketizer().\r\n    setInputCol(\"avgrating\").\r\n    setOutputCol(\"label\").\r\n    setSplits(splits).\r\n    transform(naive_ad)\r\n    \r\nval Array (ad_trainNaive, ad_testNaive) = bucketed_data3.randomSplit(Array(0.7, 0.3))\r\n\r\nval bucketed_adtrain = ad_trainNaive.select($\"userid2\", $\"artist2\", $\"avgrating\", $\"features\", $\"label\").rdd.map(row => LabeledPoint(row.getAs[Double](\"label\"), row.getAs[org.apache.spark.mllib.linalg.Vector](\"features\")))\r\n\r\nval bucketed_adtest = ad_testNaive.select($\"userid2\", $\"artist2\", $\"avgrating\", $\"features\", $\"label\").rdd.map(row => LabeledPoint(row.getAs[Double](\"label\"), row.getAs[org.apache.spark.mllib.linalg.Vector](\"features\")))\r\n   \r\nval nb_model3 = NaiveBayes.train(bucketed_adtrain, lambda = 1.0, modelType = \"multinomial\")\r\n\r\nval prediction_label3 = bucketed_adtest.map(p=> (nb_model3.predict(p.features), p.label))\r\nval accuracy = 1.0 * prediction_label3.filter(x => x._1 == x._2).count() / bucketed_adtest.count()\r\n\r\n// Instantiate metrics object\r\nval metrics = new MulticlassMetrics(prediction_label3)\r\n\r\n// Confusion matrix\r\nprintln(\"Confusion matrix:\")\r\nprintln(metrics.confusionMatrix)\r\n\r\n// Precision by label\r\nval labels = metrics.labels\r\nlabels.foreach { l =>\r\n  println(s\"Precision($l) = \" + metrics.precision(l))\r\n}\r\n\r\n// Recall by label\r\nlabels.foreach { l =>\r\n  println(s\"Recall($l) = \" + metrics.recall(l))\r\n}\r\n\r\n// False positive rate by label\r\nlabels.foreach { l =>\r\n  println(s\"FPR($l) = \" + metrics.falsePositiveRate(l))\r\n}\r\n\r\n// F-measure by label\r\nlabels.foreach { l =>\r\n  println(s\"F1-Score($l) = \" + metrics.fMeasure(l))\r\n}\r\n\r\n// Weighted stats\r\nprintln(s\"Weighted precision: ${metrics.weightedPrecision}\")\r\nprintln(s\"Weighted recall: ${metrics.weightedRecall}\")\r\nprintln(s\"Weighted F1 score: ${metrics.weightedFMeasure}\")\r\nprintln(s\"Weighted false positive rate: ${metrics.weightedFalsePositiveRate}\")","dateUpdated":"Apr 10, 2017 12:30:38 AM","config":{"enabled":true,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"colWidth":12},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1491272501870_150624004","id":"20170404-022141_754013818","result":{"code":"SUCCESS","type":"TEXT","msg":"naive_ad: org.apache.spark.sql.DataFrame = [userid2: string, artist2: string, avgrating: double, features: vector]\nsplits: Array[Double] = Array(0.0, 25.0, 50.0, 75.0, 100.0)\nbucketed_data3: org.apache.spark.sql.DataFrame = [userid2: string, artist2: string, avgrating: double, features: vector, label: double]\nad_trainNaive: org.apache.spark.sql.DataFrame = [userid2: string, artist2: string, avgrating: double, features: vector, label: double]\nad_testNaive: org.apache.spark.sql.DataFrame = [userid2: string, artist2: string, avgrating: double, features: vector, label: double]\nbucketed_adtrain: org.apache.spark.rdd.RDD[org.apache.spark.mllib.regression.LabeledPoint] = MapPartitionsRDD[1528] at map at <console>:92\nbucketed_adtest: org.apache.spark.rdd.RDD[org.apache.spark.mllib.regression.LabeledPoint] = MapPartitionsRDD[1535] at map at <console>:92\nnb_model3: org.apache.spark.mllib.classification.NaiveBayesModel = org.apache.spark.mllib.classification.NaiveBayesModel@3e7f85f3\nprediction_label3: org.apache.spark.rdd.RDD[(Double, Double)] = MapPartitionsRDD[1538] at map at <console>:100\naccuracy: Double = 0.5843023255813954\n"},"dateCreated":"Apr 4, 2017 2:21:41 AM","dateStarted":"Apr 9, 2017 4:34:07 PM","dateFinished":"Apr 9, 2017 4:35:16 PM","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:136"},{"text":"//Distribution of Ratings in Data Set\nad_trainNaive.groupBy($\"label\").agg(count($\"label\").alias(\"Count\"),((count($\"label\")/ad_trainNaive.count())*100).alias(\"Percent\")).orderBy($\"label\".asc).show()\nad_testNaive.groupBy($\"label\").agg(count($\"label\").alias(\"Count\"),((count($\"label\")/ad_testNaive.count())*100).alias(\"Percent\")).orderBy($\"label\".asc).show()\nbucketed_data3.groupBy($\"label\").agg(count($\"label\").alias(\"Count\"),((count($\"label\")/bucketed_data3.count())*100).alias(\"Percent\")).orderBy($\"label\".asc).show()","dateUpdated":"Apr 9, 2017 9:45:02 PM","config":{"colWidth":12,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true,"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1491618127971_-19015077","id":"20170408-022207_901691315","dateCreated":"Apr 8, 2017 2:22:07 AM","dateStarted":"Apr 8, 2017 2:35:47 AM","dateFinished":"Apr 8, 2017 2:36:51 AM","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:138","errorMessage":"","focus":true},{"text":"//NAIVE BAYES CLASSIFICATION OF AVERAGE RATINGS JOINED DATA - 5 Categories\nval naivejoin_avg = join_vec.select($\"userid\", $\"artist\", $\"avgrating\", $\"features\")\n\nval splits2 = Array(0.0, 20.0, 40.0, 60.0, 80.0, 100.0)\nval bucketed_data = new Bucketizer().\n    setInputCol(\"avgrating\").\n    setOutputCol(\"label\").\n    setSplits(splits2).\n    transform(naivejoin_avg)\n    \nval Array (joina_trainNaive, joina_testNaive) = bucketed_data.randomSplit(Array(0.7, 0.3))\n\nval bucketed_train = joina_trainNaive.select($\"userid\", $\"artist\", $\"avgrating\", $\"features\", $\"label\").rdd.map(row => LabeledPoint(row.getAs[Double](\"label\"), row.getAs[org.apache.spark.mllib.linalg.Vector](\"features\")))\n\nval bucketed_test = joina_testNaive.select($\"userid\", $\"artist\", $\"avgrating\", $\"features\", $\"label\").rdd.map(row => LabeledPoint(row.getAs[Double](\"label\"), row.getAs[org.apache.spark.mllib.linalg.Vector](\"features\")))\n   \nval nb_model = NaiveBayes.train(bucketed_train, lambda = 1.0, modelType = \"multinomial\")\n\nval prediction_label = bucketed_test.map(p=> (nb_model.predict(p.features), p.label))\nval accuracy = 1.0 * prediction_label.filter(x => x._1 == x._2).count() / bucketed_test.count()\n\n// Instantiate metrics object\nval metrics = new MulticlassMetrics(prediction_label)\n\n// Confusion matrix\nprintln(\"Confusion matrix:\")\nprintln(metrics.confusionMatrix)\n\n// Precision by label\nval labels = metrics.labels\nlabels.foreach { l =>\n  println(s\"Precision($l) = \" + metrics.precision(l))\n}\n\n// Recall by label\nlabels.foreach { l =>\n  println(s\"Recall($l) = \" + metrics.recall(l))\n}\n\n// False positive rate by label\nlabels.foreach { l =>\n  println(s\"FPR($l) = \" + metrics.falsePositiveRate(l))\n}\n\n// F-measure by label\nlabels.foreach { l =>\n  println(s\"F1-Score($l) = \" + metrics.fMeasure(l))\n}\n\n// Weighted stats\nprintln(s\"Weighted precision: ${metrics.weightedPrecision}\")\nprintln(s\"Weighted recall: ${metrics.weightedRecall}\")\nprintln(s\"Weighted F1 score: ${metrics.weightedFMeasure}\")\nprintln(s\"Weighted false positive rate: ${metrics.weightedFalsePositiveRate}\")","dateUpdated":"Apr 9, 2017 4:43:36 PM","config":{"enabled":true,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"colWidth":12,"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1491272501884_156010489","id":"20170404-022141_1477961362","result":{"code":"SUCCESS","type":"TEXT","msg":"naivejoin_avg: org.apache.spark.sql.DataFrame = [userid: string, artist: string, avgrating: double, features: vector]\nsplits2: Array[Double] = Array(0.0, 20.0, 40.0, 60.0, 80.0, 100.0)\nbucketed_data: org.apache.spark.sql.DataFrame = [userid: string, artist: string, avgrating: double, features: vector, label: double]\njoina_trainNaive: org.apache.spark.sql.DataFrame = [userid: string, artist: string, avgrating: double, features: vector, label: double]\njoina_testNaive: org.apache.spark.sql.DataFrame = [userid: string, artist: string, avgrating: double, features: vector, label: double]\nbucketed_train: org.apache.spark.rdd.RDD[org.apache.spark.mllib.regression.LabeledPoint] = MapPartitionsRDD[1568] at map at <console>:97\nbucketed_test: org.apache.spark.rdd.RDD[org.apache.spark.mllib.regression.LabeledPoint] = MapPartitionsRDD[1587] at map at <console>:97\nnb_model: org.apache.spark.mllib.classification.NaiveBayesModel = org.apache.spark.mllib.classification.NaiveBayesModel@31d4911e\nprediction_label: org.apache.spark.rdd.RDD[(Double, Double)] = MapPartitionsRDD[1590] at map at <console>:105\naccuracy: Double = 0.411144578313253\nmetrics: org.apache.spark.mllib.evaluation.MulticlassMetrics = org.apache.spark.mllib.evaluation.MulticlassMetrics@6b8e66ca\nConfusion matrix:\n7535.0  4489.0  540.0   102.0   560.0   \n5131.0  7113.0  3162.0  616.0   1628.0  \n1473.0  3772.0  4997.0  1546.0  2607.0  \n225.0   707.0   1768.0  1023.0  1481.0  \n37.0    166.0   526.0   353.0   899.0   \nlabels: Array[Double] = Array(0.0, 1.0, 2.0, 3.0, 4.0)\nPrecision(0.0) = 0.5232275536421082\nPrecision(1.0) = 0.43780390225887855\nPrecision(2.0) = 0.4545619939961794\nPrecision(3.0) = 0.28104395604395604\nPrecision(4.0) = 0.12529616724738676\nRecall(0.0) = 0.5697111749584153\nRecall(1.0) = 0.4030028328611898\nRecall(2.0) = 0.34713442167419245\nRecall(3.0) = 0.19657955418908532\nRecall(4.0) = 0.4538112064613831\nFPR(0.0) = 0.175019118021922\nFPR(1.0) = 0.26242601850255703\nFPR(2.0) = 0.1575365860066735\nFPR(3.0) = 0.05538389909421823\nFPR(4.0) = 0.12433878157503715\nF1-Score(0.0) = 0.5454808701632461\nF1-Score(1.0) = 0.41968315780157534\nF1-Score(2.0) = 0.39365054356388846\nF1-Score(3.0) = 0.23134328358208955\nF1-Score(4.0) = 0.19637396242900831\nWeighted precision: 0.4365874419987142\nWeighted recall: 0.4111445783132531\nWeighted F1 score: 0.4171394038034187\nWeighted false positive rate: 0.1858489815136609\n"},"dateCreated":"Apr 4, 2017 2:21:41 AM","dateStarted":"Apr 9, 2017 4:43:36 PM","dateFinished":"Apr 9, 2017 4:50:30 PM","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:144"},{"text":"//Distribution of Ratings in Data Set\njoina_testNaive.groupBy($\"label\").agg(count($\"label\").alias(\"Count\"),((count($\"label\")/joina_testNaive.count())*100).alias(\"Percent\")).orderBy($\"label\".asc).show()\njoina_trainNaive.groupBy($\"label\").agg(count($\"label\").alias(\"Count\"),((count($\"label\")/joina_trainNaive.count())*100).alias(\"Percent\")).orderBy($\"label\".asc).show()\nbucketed_data.groupBy($\"label\").agg(count($\"label\").alias(\"Count\"),((count($\"label\")/bucketed_data.count())*100).alias(\"Percent\")).orderBy($\"label\".asc).show()","dateUpdated":"Apr 9, 2017 9:40:04 PM","config":{"colWidth":12,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true,"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1491612889771_565329323","id":"20170408-005449_1925552061","dateCreated":"Apr 8, 2017 12:54:49 AM","dateStarted":"Apr 9, 2017 9:31:51 PM","dateFinished":"Apr 9, 2017 9:36:11 PM","status":"ERROR","progressUpdateIntervalMs":500,"$$hashKey":"object:146","errorMessage":"","focus":true},{"text":"//NAIVE BAYES CLASSIFICATION OF RATINGS USING ARTIST DESCRIPTORS ONLY - 5 Categories\r\nval naive_ad = ad_vec.select($\"userid2\", $\"artist2\", $\"avgrating\", $\"features\")\r\n\r\nval splits = Array(0.0, 20.0, 40.0, 60.0, 80.0, 100.0)\r\nval bucketed_data5 = new Bucketizer().\r\n    setInputCol(\"avgrating\").\r\n    setOutputCol(\"label\").\r\n    setSplits(splits).\r\n    transform(naive_ad)\r\n    \r\nval Array (ad_trainNaive, ad_testNaive) = bucketed_data5.randomSplit(Array(0.7, 0.3))\r\n\r\nval bucketed_adtrain = ad_trainNaive.select($\"userid2\", $\"artist2\", $\"avgrating\", $\"features\", $\"label\").rdd.map(row => LabeledPoint(row.getAs[Double](\"label\"), row.getAs[org.apache.spark.mllib.linalg.Vector](\"features\")))\r\n\r\nval bucketed_adtest = ad_testNaive.select($\"userid2\", $\"artist2\", $\"avgrating\", $\"features\", $\"label\").rdd.map(row => LabeledPoint(row.getAs[Double](\"label\"), row.getAs[org.apache.spark.mllib.linalg.Vector](\"features\")))\r\n   \r\nval nb_model5 = NaiveBayes.train(bucketed_adtrain, lambda = 1.0, modelType = \"multinomial\")\r\n\r\nval prediction_label5 = bucketed_adtest.map(p=> (nb_model5.predict(p.features), p.label))\r\nval accuracy = 1.0 * prediction_label5.filter(x => x._1 == x._2).count() / bucketed_adtest.count()\r\n\r\n// Instantiate metrics object\r\nval metrics = new MulticlassMetrics(prediction_label5)\r\n\r\n// Confusion matrix\r\nprintln(\"Confusion matrix:\")\r\nprintln(metrics.confusionMatrix)\r\n\r\n// Precision by label\r\nval labels = metrics.labels\r\nlabels.foreach { l =>\r\n  println(s\"Precision($l) = \" + metrics.precision(l))\r\n}\r\n\r\n// Recall by label\r\nlabels.foreach { l =>\r\n  println(s\"Recall($l) = \" + metrics.recall(l))\r\n}\r\n\r\n// False positive rate by label\r\nlabels.foreach { l =>\r\n  println(s\"FPR($l) = \" + metrics.falsePositiveRate(l))\r\n}\r\n\r\n// F-measure by label\r\nlabels.foreach { l =>\r\n  println(s\"F1-Score($l) = \" + metrics.fMeasure(l))\r\n}\r\n\r\n// Weighted stats\r\nprintln(s\"Weighted precision: ${metrics.weightedPrecision}\")\r\nprintln(s\"Weighted recall: ${metrics.weightedRecall}\")\r\nprintln(s\"Weighted F1 score: ${metrics.weightedFMeasure}\")\r\nprintln(s\"Weighted false positive rate: ${metrics.weightedFalsePositiveRate}\")","dateUpdated":"Apr 9, 2017 9:49:05 PM","config":{"colWidth":12,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1491436307632_-2019172733","id":"20170405-235147_153291701","result":{"code":"SUCCESS","type":"TEXT","msg":"naive_ad: org.apache.spark.sql.DataFrame = [userid2: string, artist2: string, avgrating: double, features: vector]\nsplits: Array[Double] = Array(0.0, 20.0, 40.0, 60.0, 80.0, 100.0)\nbucketed_data5: org.apache.spark.sql.DataFrame = [userid2: string, artist2: string, avgrating: double, features: vector, label: double]\nad_trainNaive: org.apache.spark.sql.DataFrame = [userid2: string, artist2: string, avgrating: double, features: vector, label: double]\nad_testNaive: org.apache.spark.sql.DataFrame = [userid2: string, artist2: string, avgrating: double, features: vector, label: double]\nbucketed_adtrain: org.apache.spark.rdd.RDD[org.apache.spark.mllib.regression.LabeledPoint] = MapPartitionsRDD[1608] at map at <console>:97\nbucketed_adtest: org.apache.spark.rdd.RDD[org.apache.spark.mllib.regression.LabeledPoint] = MapPartitionsRDD[1615] at map at <console>:97\nnb_model5: org.apache.spark.mllib.classification.NaiveBayesModel = org.apache.spark.mllib.classification.NaiveBayesModel@402252c1\nprediction_label5: org.apache.spark.rdd.RDD[(Double, Double)] = MapPartitionsRDD[1618] at map at <console>:105\naccuracy: Double = 0.5020788234889874\nmetrics: org.apache.spark.mllib.evaluation.MulticlassMetrics = org.apache.spark.mllib.evaluation.MulticlassMetrics@648073e7\nConfusion matrix:\n5760.0  1290.0  643.0   1.0    0.0   \n3125.0  2581.0  3518.0  27.0   0.0   \n487.0   1371.0  6004.0  159.0  3.0   \n45.0    262.0   2388.0  239.0  23.0  \n11.0    69.0    817.0   252.0  28.0  \nlabels: Array[Double] = Array(0.0, 1.0, 2.0, 3.0, 4.0)\nPrecision(0.0) = 0.6109461179465422\nPrecision(1.0) = 0.46312578503499013\nPrecision(2.0) = 0.44906507105459986\nPrecision(3.0) = 0.3525073746312684\nPrecision(4.0) = 0.5185185185185185\nRecall(0.0) = 0.7486353002339485\nRecall(1.0) = 0.27899686520376177\nRecall(2.0) = 0.7482552342971087\nRecall(3.0) = 0.0808251606357795\nRecall(4.0) = 0.0237892948173322\nFPR(0.0) = 0.17132981456396842\nFPR(1.0) = 0.15071529316945395\nFPR(2.0) = 0.349447317235163\nFPR(3.0) = 0.016790331217012164\nFPR(4.0) = 9.310320131776839E-4\nF1-Score(0.0) = 0.6728185959584161\nF1-Score(1.0) = 0.3482191041554237\nF1-Score(2.0) = 0.5612788632326822\nF1-Score(3.0) = 0.1314993122420908\nF1-Score(4.0) = 0.045491470349309504\nWeighted precision: 0.48932944377082965\nWeighted recall: 0.5020788234889875\nWeighted F1 score: 0.45851388981637353\nWeighted false positive rate: 0.1912926116877626\n"},"dateCreated":"Apr 5, 2017 11:51:47 PM","dateStarted":"Apr 9, 2017 4:57:28 PM","dateFinished":"Apr 9, 2017 4:59:28 PM","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:147"},{"config":{"colWidth":12,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1491437696910_1979527519","id":"20170406-001456_2084542290","dateCreated":"Apr 6, 2017 12:14:56 AM","status":"ERROR","progressUpdateIntervalMs":500,"$$hashKey":"object:148","dateUpdated":"Apr 9, 2017 9:46:31 PM","dateFinished":"Apr 9, 2017 9:43:01 PM","dateStarted":"Apr 9, 2017 9:42:29 PM","errorMessage":"","text":"//Distribution of Ratings in Data Set\nad_trainNaive.groupBy($\"label\").agg(count($\"label\").alias(\"Count\"),((count($\"label\")/ad_trainNaive.count())*100).alias(\"Percent\")).orderBy($\"label\".asc).show()\nad_testNaive.groupBy($\"label\").agg(count($\"label\").alias(\"Count\"),((count($\"label\")/ad_testNaive.count())*100).alias(\"Percent\")).orderBy($\"label\".asc).show()\nbucketed_data5.groupBy($\"label\").agg(count($\"label\").alias(\"Count\"),((count($\"label\")/bucketed_data5.count())*100).alias(\"Percent\")).orderBy($\"label\".asc).show()","focus":true},{"config":{"colWidth":12,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true,"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1491774148918_1025342148","id":"20170409-214228_961304721","dateCreated":"Apr 9, 2017 9:42:28 PM","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:1732","dateUpdated":"Apr 10, 2017 12:38:00 AM","dateFinished":"Apr 10, 2017 12:41:26 AM","dateStarted":"Apr 10, 2017 12:38:00 AM","result":{"code":"SUCCESS","type":"TEXT","msg":"selUser: Int = 25600\nres825: org.apache.spark.sql.DataFrame = [result: string]\nu: org.apache.spark.sql.DataFrame = [userid: string, artist: string, track: string, rating: double, time: int, gender: string, age: int, workingstatus: string, region: string, music: string, list_own: string, list_back: string, q1: int, q2: int, q3: int, q4: int, q5: int, q6: int, q7: int, q8: int, q9: int, q10: int, q11: int, q12: int, q13: int, q14: int, q15: int, q16: int, q17: int, q18: int, q19: int, list_own2: int, list_back2: int, usercluster: int]\nad: org.apache.spark.sql.DataFrame = [userid2: string, artist2: string, avgrating: double, heard_of: string, own_artist: string, like_artist: string, aggressive: int, edgy: int, thoughtful: int, serious: int, goodlyrics: int, unattractive: int, confident: int, youthful: int, boring: int, current2: int, cheap: int, calm: int, outgoing: int, inspiring: int, beautiful: int, fun: int, authentic: int, credible: int, cool: int, catchy: int, sensitive: int, superficial: int, passionate: int, timeless: int, depressing: int, original: int, talented: int, distinctive: int, approachable: int, trendsetter: int, noisy: int, upbeat: int, energetic: int, none_of_these: int, sexy: int, over2: int, fake: int, cheesy: int, unoriginal: int, dated: int, unapproachable: int, classic: int, playful: int, arro...r: org.apache.spark.sql.DataFrame = [artist: int, track: int, userid: int, rating: double, time: int]\nratedArtists: org.apache.spark.sql.DataFrame = [artist: int, track: int, userid: int, rating: double, time: int]\nl: org.apache.spark.sql.DataFrame = [artist: int]\nunRated: org.apache.spark.sql.DataFrame = [userid2: string, artist2: string, avgrating: double, heard_of: string, own_artist: string, like_artist: string, aggressive: int, edgy: int, thoughtful: int, serious: int, goodlyrics: int, unattractive: int, confident: int, youthful: int, boring: int, current2: int, cheap: int, calm: int, outgoing: int, inspiring: int, beautiful: int, fun: int, authentic: int, credible: int, cool: int, catchy: int, sensitive: int, superficial: int, passionate: int, timeless: int, depressing: int, original: int, talented: int, distinctive: int, approachable: int, trendsetter: int, noisy: int, upbeat: int, energetic: int, none_of_these: int, sexy: int, over2: int, fake: int, cheesy: int, unoriginal: int, dated: int, unapproachable: int, classic: int, playful: int,...userProfile: org.apache.spark.sql.DataFrame = [userid: string, gender: string, age: int, workingStatus: string, region: string, music: string, Q1: int, Q2: int, Q3: int, Q4: int, Q5: int, Q6: int, Q7: int, Q8: int, Q9: int, Q10: int, Q11: int, Q12: int, Q13: int, Q14: int, Q15: int, Q16: int, Q17: int, Q18: int, Q19: int, List_Own2: int, List_Back2: int, genderIndex: double, musicIndex: double, usercluster: int]\nrecommendations: org.apache.spark.sql.DataFrame = [userid: string, gender: string, age: int, workingStatus: string, region: string, music: string, Q1: int, Q2: int, Q3: int, Q4: int, Q5: int, Q6: int, Q7: int, Q8: int, Q9: int, Q10: int, Q11: int, Q12: int, Q13: int, Q14: int, Q15: int, Q16: int, Q17: int, Q18: int, Q19: int, List_Own2: int, List_Back2: int, genderIndex: double, musicIndex: double, usercluster: int, userid2: string, artist2: string, avgrating: double, heard_of: string, own_artist: string, like_artist: string, aggressive: int, edgy: int, thoughtful: int, serious: int, goodlyrics: int, unattractive: int, confident: int, youthful: int, boring: int, current2: int, cheap: int, calm: int, outgoing: int, inspiring: int, beautiful: int, fun: int, authentic: int, credible: int, ...features: Array[String] = Array(genderIndex, musicIndex, Q1, Q2, Q3, Q4, Q7, Q8, Q10, Q11, Q12, Q13, Q14, Q15, Q16, Q17, Q18, Q19, heardIndex, aggressive, edgy, thoughtful, serious, goodlyrics, unattractive, confident, youthful, boring, current2, cheap, calm, outgoing, inspiring, beautiful, fun, authentic, credible, cool, catchy, sensitive, superficial, passionate, timeless, depressing, original, talented, distinctive, approachable, trendsetter, noisy, upbeat, energetic, none_of_these, sexy, over2, fake, cheesy, unoriginal, dated, unapproachable, classic, playful, arrogant, warm)\nrecommendations_vec: org.apache.spark.sql.DataFrame = [userid: string, gender: string, age: int, workingStatus: string, region: string, music: string, Q1: int, Q2: int, Q3: int, Q4: int, Q5: int, Q6: int, Q7: int, Q8: int, Q9: int, Q10: int, Q11: int, Q12: int, Q13: int, Q14: int, Q15: int, Q16: int, Q17: int, Q18: int, Q19: int, List_Own2: int, List_Back2: int, genderIndex: double, musicIndex: double, usercluster: int, userid2: string, artist2: string, avgrating: double, heard_of: string, own_artist: string, like_artist: string, aggressive: int, edgy: int, thoughtful: int, serious: int, goodlyrics: int, unattractive: int, confident: int, youthful: int, boring: int, current2: int, cheap: int, calm: int, outgoing: int, inspiring: int, beautiful: int, fun: int, authentic: int, credible: i...recoModel: org.apache.spark.ml.regression.LinearRegressionModel = linReg_15b6f823c763\npredictedRatings: org.apache.spark.sql.DataFrame = [userid: string, gender: string, age: int, workingStatus: string, region: string, music: string, Q1: int, Q2: int, Q3: int, Q4: int, Q5: int, Q6: int, Q7: int, Q8: int, Q9: int, Q10: int, Q11: int, Q12: int, Q13: int, Q14: int, Q15: int, Q16: int, Q17: int, Q18: int, Q19: int, List_Own2: int, List_Back2: int, genderIndex: double, musicIndex: double, usercluster: int, userid2: string, artist2: string, avgrating: double, heard_of: string, own_artist: string, like_artist: string, aggressive: int, edgy: int, thoughtful: int, serious: int, goodlyrics: int, unattractive: int, confident: int, youthful: int, boring: int, current2: int, cheap: int, calm: int, outgoing: int, inspiring: int, beautiful: int, fun: int, authentic: int, credible: int,...usersRecommendations: org.apache.spark.sql.DataFrame = [artist2: string, avgRating: double]\npredictedRatings: org.apache.spark.sql.DataFrame = [userid: string, gender: string, age: int, workingStatus: string, region: string, music: string, Q1: int, Q2: int, Q3: int, Q4: int, Q5: int, Q6: int, Q7: int, Q8: int, Q9: int, Q10: int, Q11: int, Q12: int, Q13: int, Q14: int, Q15: int, Q16: int, Q17: int, Q18: int, Q19: int, List_Own2: int, List_Back2: int, genderIndex: double, musicIndex: double, usercluster: int, userid2: string, artist2: string, avgrating: double, heard_of: string, own_artist: string, like_artist: string, aggressive: int, edgy: int, thoughtful: int, serious: int, goodlyrics: int, unattractive: int, confident: int, youthful: int, boring: int, current2: int, cheap: int, calm: int, outgoing: int, inspiring: int, beautiful: int, fun: int, authentic: int, credible: int,...usersRecommendations: org.apache.spark.sql.DataFrame = [artist2: string, avgRating: double]\nHello 25600! Here are some other Artists you might like:\n+-------+\n|artist2|\n+-------+\n|      4|\n|      7|\n|     43|\n|      8|\n|     22|\n|     44|\n|     45|\n|     41|\n|     17|\n|     12|\n+-------+\nonly showing top 10 rows\n\n"},"text":"//SELECT PREDICTIONS FOR USER\n//Select Rated Artists\nval selUser = 25600\n\nsqlContext.sql(\"use recommender\")\nval u = sqlContext.table(\"userData\")\nval ad = sqlContext.table(\"wordsRating\")\nval r = sqlContext.table(\"ratings\")\n\nval ratedArtists = r.select($\"*\").filter($\"userId\" === selUser)\n\nval l = ratedArtists.select($\"artist\").distinct\n\nval unRated = ad4.join(l, ad4(\"artist2\") !== l(\"artist\"))\n\n//Select Users Profile\nval userProfile = u_vec.select($\"userid\", $\"gender\", $\"age\", $\"workingStatus\", $\"region\", $\"music\", $\"Q1\", $\"Q2\", $\"Q3\", $\"Q4\", $\"Q5\", $\"Q6\", $\"Q7\", $\"Q8\", $\"Q9\", $\"Q10\", $\"Q11\", $\"Q12\", $\"Q13\", $\"Q14\", $\"Q15\", $\"Q16\", $\"Q17\", $\"Q18\", $\"Q19\", $\"List_Own2\", $\"List_Back2\", $\"genderIndex\", $\"musicIndex\", $\"usercluster\").filter($\"userid\" === selUser).limit(1)\n\nval recommendations = userProfile.join(unRated)\n\n//Predict Artist Ratings\n//Create Array of Features variables\nval features = Array(\"genderIndex\", \"musicIndex\", \"Q1\", \"Q2\", \"Q3\", \"Q4\", \"Q7\", \"Q8\", \"Q10\", \"Q11\", \"Q12\", \"Q13\", \"Q14\", \"Q15\", \"Q16\", \"Q17\", \"Q18\", \"Q19\",\"heardIndex\", \"aggressive\", \"edgy\", \"thoughtful\", \"serious\", \"goodlyrics\", \"unattractive\", \"confident\", \"youthful\", \"boring\", \"current2\", \"cheap\", \"calm\", \"outgoing\", \"inspiring\", \"beautiful\", \"fun\", \"authentic\", \"credible\", \"cool\", \"catchy\", \"sensitive\", \"superficial\", \"passionate\", \"timeless\", \"depressing\", \"original\", \"talented\", \"distinctive\", \"approachable\", \"trendsetter\", \"noisy\", \"upbeat\", \"energetic\", \"none_of_these\", \"sexy\", \"over2\", \"fake\", \"cheesy\", \"unoriginal\", \"dated\", \"unapproachable\", \"classic\", \"playful\", \"arrogant\", \"warm\")\n\n//Create Vector of Features\nval recommendations_vec = new VectorAssembler().\n    setInputCols(features).\n    setOutputCol(\"features\").\n    transform(recommendations)\n    \n//Load Model\nval recoModel = LinearRegressionModel.load(\"/user/lab/CapstoneProj/joinedAvgRegModel\")\n\nval predictedRatings = recoModel.transform(recommendations_vec)\nval usersRecommendations = predictedRatings.select($\"artist2\", $\"prediction\").groupBy($\"artist2\").agg(avg($\"prediction\").alias(\"avgRating\")).orderBy($\"avgRating\".desc)\n\nval predictedRatings = recoModel.transform(recommendations_vec)\nval usersRecommendations = predictedRatings.select($\"artist2\", $\"prediction\").groupBy($\"artist2\").agg(avg($\"prediction\").alias(\"avgRating\")).orderBy($\"avgRating\".desc)\n\nprintln(\"Hello \" + selUser + \"! Here are some other Artists you might like:\")\nusersRecommendations.select($\"artist2\").show(10)"},{"config":{"colWidth":12,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1491784680685_-516395736","id":"20170410-003800_327054876","dateCreated":"Apr 10, 2017 12:38:00 AM","status":"READY","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:1912"}],"name":"Capstone Project Recommender System","id":"2CDCBACRY","angularObjects":{"2CE3P2MKQ":[],"2CBW2RQQQ":[],"2CD3F2R43":[],"2CDS8XR3Q":[],"2CEMZ2YZW":[],"2CEB32HFZ":[],"2CD3EPWE1":[],"2CCRRRMNN":[],"2CD5CR4KC":[],"2CD9HZPXW":[],"2CDEXCW1K":[],"2CCFHVKC4":[],"2CCGCX2UD":[]},"config":{"looknfeel":"default"},"info":{}}